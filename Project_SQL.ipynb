{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. База данных для хранения исходных данных, промежуточных и окончательных результатов.\n",
    "Создано в DB Browser for SQLite:\n",
    "\n",
    "CREATE TABLE \"Sentences\" (\n",
    "\t\"ID\"\tINTEGER,\n",
    "\t\"Sentence\"\tTEXT,\n",
    "\t\"Metadata\"\tTEXT,\n",
    "\tPRIMARY KEY(\"ID\" AUTOINCREMENT)\n",
    ")\n",
    "CREATE TABLE \"Words\" (\n",
    "\t\"ID\"\tINTEGER,\n",
    "\t\"Token\"\tTEXT,\n",
    "\t\"Lemma\"\tTEXT,\n",
    "\t\"POS\"\tTEXT,\n",
    "\t\"ID_sent\"\tINTEGER,\n",
    "\tPRIMARY KEY(\"ID\" AUTOINCREMENT)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('DoctorWho.db')\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для коллекции предложений connlu идёт первичная итерация по предложениям sent с метадатой meta, вторичная итерация по токенам token с леммой lemma и тегом tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dicts = [[{'id': 1, 'text': 'Test', 'upos': 'NOUN', 'xpos': 'NN', 'feats': 'Number=Sing', 'misc': 'start_char=0|end_char=4'}, {'id': 2, 'text': 'sentence', 'upos': 'NOUN', 'xpos': 'NN', 'feats': 'Number=Sing', 'misc': 'start_char=5|end_char=13'}, {'id': 3, 'text': '.', 'upos': 'PUNCT', 'xpos': '.', 'misc': 'start_char=13|end_char=14'}]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пишем данные в базу\n",
    "id_sent = 1\n",
    "id_token = 1\n",
    "for line in connlu:\n",
    "    # meta = \n",
    "    # sent = \n",
    "    cur.execute(\n",
    "            \"\"\"\n",
    "            INSERT INTO Sentences\n",
    "                VALUES (?,?,?)\n",
    "            \"\"\", (id_sent,sent,meta) # id, предложение, метадата\n",
    "    conn.commit()\n",
    "    # for word in sent:\n",
    "        # token =\n",
    "        # lemma = \n",
    "        # tag = \n",
    "        cur.execute(\n",
    "            \"\"\"\n",
    "            INSERT INTO Words\n",
    "                VALUES (?,?,?,?)\n",
    "            \"\"\", (id_token,token,lemma,tag,id_sent) # id, токен, лемма, тег, id предложения, из которго взято слово\n",
    "        conn.commit()\n",
    "        id_token +=1\n",
    "     id_sent += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# request = [([entry], search_type)], search_type IN token, lemma, POS, (lemma,POS)\n",
    "# Если нужна последовательность из 2-3 слов\n",
    "# Вынимаем из базы  ID-шники предложений, в которых встречаются искомые вхождения и ID-шники самих вхождений\n",
    "def search_sequence(request):\n",
    "    i = 1\n",
    "    output = []\n",
    "    for entry in request:\n",
    "        if entry[1] != 'lemma+pos':\n",
    "            query = 'SELECT ID_sent, ID FROM Words WHERE Words.'+ entry[1]+ '='  + entry[0][1]\n",
    "        else:\n",
    "            query = 'SELECT ID_sent, ID FROM Words WHERE Words.'+ entry[1][0]+ '='  + entry[0][0] + 'AND Words.'+ entry[1][1]+ '=' + entry[0][1]\n",
    "        i +=1\n",
    "        res = cur.execute(query)\n",
    "        res.fetchall()\n",
    "        output.append(res)\n",
    "    return(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# request = [([entry], search_type)], search_type IN token, lemma, POS, (lemma,POS)\n",
    "# Если нужно одно слово - сразу вынимаем из базы предложения и метадату\n",
    "def search_one(request):\n",
    "    if request[0][1] != 'lemma+pos':\n",
    "        query = 'SELECT Sentence, Metadata FROM Sentences JOIN Words ON Words.ID_sent = Sentences.ID WHERE Words.' + request[1][0]+ '=' + request[0][0]\n",
    "    else:\n",
    "        query = 'SELECT Sentence, Metadata FROM Sentences JOIN Words ON Words.ID_sent = Sentences.ID WHERE Words.' + request[1][0]+ '=' + request[0][0]+ 'AND Words.' + request[1][1]+ '=' + request[0][1]\n",
    "    res = cur.execute(query)\n",
    "    res.fetchall()\n",
    "    return(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'request' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/kryakwa/Documents/Python/python_for_nlp_stud/homework/Project_SQL.ipynb Cell 10\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kryakwa/Documents/Python/python_for_nlp_stud/homework/Project_SQL.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# request = [([entry], search_type)], search_type IN token, lemma, POS, (lemma,POS)\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/kryakwa/Documents/Python/python_for_nlp_stud/homework/Project_SQL.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(request) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kryakwa/Documents/Python/python_for_nlp_stud/homework/Project_SQL.ipynb#X24sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     output \u001b[39m=\u001b[39m search_one(request)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kryakwa/Documents/Python/python_for_nlp_stud/homework/Project_SQL.ipynb#X24sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'request' is not defined"
     ]
    }
   ],
   "source": [
    "# request = [([entry], search_type)], search_type IN token, lemma, POS, (lemma,POS)\n",
    "if len(request) == 1:\n",
    "    output = search_one(request)\n",
    "else:\n",
    "    output = search_sequence(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = cur.execute(\"SELECT score FROM movie\")\n",
    "\n",
    "res.fetchall()\n",
    "[(8.2,), (7.5,)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>проверочное предложение</td>\n",
       "      <td>Доктор Кто, фанфик 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Sentence              Metadata\n",
       "0  проверочное предложение  Доктор Кто, фанфик 1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_by_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# поиск по словоформе requested_token\n",
    "token_query = \"\"\"\n",
    "        SELECT\n",
    "            Sentence,\n",
    "            Metadata\n",
    "        FROM Sentences\n",
    "            JOIN Words ON Words.ID_sent = Sentences.ID\n",
    "        WHERE\n",
    "            Words.token = ?\n",
    "        \"\"\"\n",
    "sentences_by_token = pd.read_sql_query(token_query, params = [requested_token], con=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>проверочное предложение</td>\n",
       "      <td>Доктор Кто, фанфик 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Sentence              Metadata\n",
       "0  проверочное предложение  Доктор Кто, фанфик 1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma_pos_request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# поиск по лемме requested_lemma\n",
    "requested_lemma = 'проверочный'\n",
    "lemma_query = \"\"\"\n",
    "        SELECT\n",
    "            Sentence,\n",
    "            Metadata\n",
    "        FROM Sentences\n",
    "            JOIN Words ON Words.ID_sent = Sentences.ID\n",
    "        WHERE\n",
    "            Words.lemma = ?\n",
    "        \"\"\"\n",
    "lemma_request = pd.read_sql_query(lemma_query, params = [requested_lemma], con=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# поиск по тегу requested_pos\n",
    "requested_pos = 'ADJ'\n",
    "pos_query = \"\"\"\n",
    "        SELECT\n",
    "            Sentence,\n",
    "            Metadata\n",
    "        FROM Sentences\n",
    "            JOIN Words ON Words.ID_sent = Sentences.ID\n",
    "        WHERE\n",
    "            Words.POS = ?\n",
    "        \"\"\"\n",
    "pos_request = pd.read_sql_query(pos_query, params = [requested_pos], con=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# поиск по тегу requested_pos, лемме requested_lemma\n",
    "requested_lemma = 'проверочный'\n",
    "requested_pos = 'ADJ'\n",
    "lemma_pos_query = \"\"\"\n",
    "        SELECT\n",
    "            Sentence,\n",
    "            Metadata\n",
    "        FROM Sentences\n",
    "            JOIN Words ON Words.ID_sent = Sentences.ID\n",
    "        WHERE\n",
    "            Words.lemma = ? AND Words.POS = ?  \n",
    "        \"\"\"\n",
    "lemma_pos_request = pd.read_sql_query(lemma_pos_query, params = [requested_lemma, requested_pos], con=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

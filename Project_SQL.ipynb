{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. База данных для хранения исходных данных, промежуточных и окончательных результатов.\n",
    "Создано в DB Browser for SQLite:\n",
    "\n",
    "CREATE TABLE \"Sentences\" (\n",
    "\t\"ID\"\tINTEGER,\n",
    "\t\"Sentence\"\tTEXT,\n",
    "\t\"Metadata\"\tTEXT,\n",
    "\tPRIMARY KEY(\"ID\" AUTOINCREMENT)\n",
    ")\n",
    "CREATE TABLE \"Words\" (\n",
    "\t\"ID\"\tINTEGER,\n",
    "\t\"Token\"\tTEXT,\n",
    "\t\"Lemma\"\tTEXT,\n",
    "\t\"POS\"\tTEXT,\n",
    "\t\"ID_sent\"\tINTEGER,\n",
    "\tPRIMARY KEY(\"ID\" AUTOINCREMENT)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from conllu import parse\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('DoctorWho.db')\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для коллекции предложений conllu идёт первичная итерация по предложениям sent с метадатой meta, вторичная итерация по токенам token с леммой lemma и тегом tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пишем данные в базу\n",
    "id_sent = 1\n",
    "id_token = 1\n",
    "for file in listdir('fics_conllus/conllu'):\n",
    "    filename = 'fics_conllus/conllu/' + file\n",
    "    with open(filename) as f:\n",
    "        text = f.read()\n",
    "    tokens = parse(text)\n",
    "    for line in tokens:\n",
    "        meta = 'test'\n",
    "        sent = str(line.metadata['text'])\n",
    "        cur.execute(\"INSERT INTO Sentences VALUES (?,?,?)\", (id_sent, sent, meta)) # id, предложение, метадата\n",
    "        for word in line:\n",
    "            token = word['form'].lower()\n",
    "            lemma = word['lemma']\n",
    "            tag = word['upos']\n",
    "            if tag != 'PUNCT':\n",
    "                cur.execute(\n",
    "                    \"\"\"\n",
    "                        INSERT INTO Words\n",
    "                        VALUES (?,?,?,?,?)\n",
    "                    \"\"\", (id_token,token,lemma,tag,id_sent)) # id, токен, лемма, тег, id предложения, из которго взято слово\n",
    "                id_token +=1\n",
    "        id_sent += 1\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# request = [([entry], search_type)], search_type IN token, lemma, POS, (lemma,POS)\n",
    "# Если нужна последовательность из 2-3 слов\n",
    "# Вынимаем из базы  ID предложений, в которых встречаются искомые вхождения и ID самих вхождений\n",
    "def search_sequence(request):\n",
    "    i = 1\n",
    "    output = []\n",
    "    for entry in request:\n",
    "        if entry[1] != 'lemma+pos':\n",
    "            query = 'SELECT ID_sent, ID FROM Words WHERE Words.'+ entry[1]+ '=\"'  + entry[0][0] +'\"'\n",
    "        else:\n",
    "            query = 'SELECT ID_sent, ID FROM Words WHERE Words.lemma=\"'  + entry[0][0] + '\"AND Words.POS=\"' + entry[0][1]+'\"'\n",
    "        i +=1\n",
    "        res = cur.execute(query)\n",
    "        output.append(res.fetchall())\n",
    "    return(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Продолжение поиска последовательности из 2-3 слов\n",
    "# Из предыдущей функции мы получили для каждого запроса список пар (ID предложений, в которых встречаются искомые вхождения, ID самих вхождений)\n",
    "# и сложили их в список второго уровня, из двух или трёх элементов. Собираем теперь словарь нужных нам предложений. \n",
    "def merge_sequence(one, two, first = {}):\n",
    "    res = {}\n",
    "    second = {}\n",
    "    if not first:\n",
    "        for entry in one:\n",
    "            if entry[0] not in first.keys():\n",
    "                first[entry[0]] = [entry[1]+1]\n",
    "            else:\n",
    "                first[entry[0]].append(entry[1]+1)\n",
    "    else:\n",
    "        for entry in two:\n",
    "             if entry[0] in first.keys():\n",
    "                if entry[0] not in second.keys():\n",
    "                     second[entry[0]] = [entry[1]]\n",
    "                else:\n",
    "                    second[entry[0]].append(entry[1])\n",
    "        for key in first.keys():\n",
    "            for value in first[key]:\n",
    "                value += 1\n",
    "    for key in first.keys():\n",
    "        if set(first[key]) & set(second[key]):\n",
    "            res[key] = set(first[key]) & set(second[key])\n",
    "    return(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# request = [([entry], search_type)], search_type IN token, lemma, POS, (lemma,POS)\n",
    "# Если нужно одно слово - сразу вынимаем из базы предложения и метадату\n",
    "def search_one(request):\n",
    "    if request[0][1] != 'lemma+pos':\n",
    "        query = 'SELECT Sentence, Metadata FROM Sentences JOIN Words ON Words.ID_sent = Sentences.ID WHERE Words.' + request[0][1]+ '=\"' + request[0][0][0]+'\"'\n",
    "    else:\n",
    "        query = 'SELECT Sentence, Metadata FROM Sentences JOIN Words ON Words.ID_sent = Sentences.ID WHERE Words.lemma' + '=\"' + request[0][0][0]+ '\" AND Words.POS' + '=\"' + request[0][0][1] + '\"'\n",
    "    res = cur.execute(query)\n",
    "    result = res.fetchall()\n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test of functions\n",
    "# search one\n",
    "lemma_search = [(['парень'], 'lemma')]\n",
    "token_search = [(['парня'], 'token')]\n",
    "pos_search = [(['NOUN'], 'POS')]\n",
    "lemma_pos_search = [(['парень','NOUN'], 'lemma+pos')]\n",
    "# sequence search\n",
    "long_search = [(['парень'], 'lemma'), (['парень','NOUN'], 'lemma+pos')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lemma'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_search[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(1, 5), (5, 43), (12, 106), (19, 152), (30, 286), (37, 349)],\n",
       " [(1, 5), (5, 43), (12, 106), (19, 152), (30, 286), (37, 349)]]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_sequence(long_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "no such column: парень",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m/home/kryakwa/Documents/Python/python_for_nlp_stud/homework/Project_SQL.ipynb Cell 12\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kryakwa/Documents/Python/python_for_nlp_stud/homework/Project_SQL.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m request \u001b[39m=\u001b[39m lemma_search\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kryakwa/Documents/Python/python_for_nlp_stud/homework/Project_SQL.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(request) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/kryakwa/Documents/Python/python_for_nlp_stud/homework/Project_SQL.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     output \u001b[39m=\u001b[39m search_one(request)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kryakwa/Documents/Python/python_for_nlp_stud/homework/Project_SQL.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mprint\u001b[39m(output)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kryakwa/Documents/Python/python_for_nlp_stud/homework/Project_SQL.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;32m/home/kryakwa/Documents/Python/python_for_nlp_stud/homework/Project_SQL.ipynb Cell 12\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kryakwa/Documents/Python/python_for_nlp_stud/homework/Project_SQL.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kryakwa/Documents/Python/python_for_nlp_stud/homework/Project_SQL.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     query \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mSELECT Sentence, Metadata FROM Sentences JOIN Words ON Words.ID_sent = Sentences.ID WHERE Words.lemma\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m request[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39mAND Words.POS\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m request[\u001b[39m0\u001b[39m][\u001b[39m1\u001b[39m]\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/kryakwa/Documents/Python/python_for_nlp_stud/homework/Project_SQL.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m res \u001b[39m=\u001b[39m cur\u001b[39m.\u001b[39;49mexecute(query)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kryakwa/Documents/Python/python_for_nlp_stud/homework/Project_SQL.ipynb#X12sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m res\u001b[39m.\u001b[39mfetchall()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kryakwa/Documents/Python/python_for_nlp_stud/homework/Project_SQL.ipynb#X12sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mreturn\u001b[39;00m(res)\n",
      "\u001b[0;31mOperationalError\u001b[0m: no such column: парень"
     ]
    }
   ],
   "source": [
    "# request = [([entry], search_type)], search_type IN token, lemma, POS, (lemma,POS)\n",
    "request = lemma_search\n",
    "if len(request) == 1:\n",
    "    output = search_one(request)\n",
    "    print(output)\n",
    "else:\n",
    "    output = search_sequence(request)\n",
    "    l = len(output)\n",
    "    flag = True\n",
    "    for i in range(l-1):\n",
    "        if flag:\n",
    "            result = merge_sequence(output[i], output[i+1])\n",
    "            flag = False\n",
    "        else:\n",
    "            result = merge_sequence(output[i], output[i+1], result)\n",
    "    if result:\n",
    "        output = cur.executemany(\"SELECT Sentence, Metadata FROM Sentences JOIN Words ON Words.ID_sent = Sentences.ID WHERE Words.ID = ?\", result.keys())\n",
    "        output.fetchall()\n",
    "    else:\n",
    "        output = \"Sorry, no matches to your request\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
